{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Spark ML on DashDB sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary Spark classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.clustering.KMeans\n",
    "import org.apache.spark.ml.clustering.KMeansModel\n",
    "import org.apache.spark.ml.feature.VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the TRAINING sample. This table is pre-populated in dashDB local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val data = spark.read.format(\"com.ibm.idax.spark.idaxsource\").\n",
    "    option(\"url\", \"jdbc:db2:BLUDB\").\n",
    "    option(\"dbtable\", \"SAMPLES.TRAINING\").\n",
    "    option(\"mode\", \"JDBC\").\n",
    "    load()\n",
    "println(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Spark ML pipeline that selects the call counts from the customer data and clusters them using KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val assembler = new VectorAssembler().\n",
    "    setInputCols(Array(\"INTL_CALLS\", \"DAY_CALLS\", \"EVE_CALLS\", \"NIGHT_CALLS\")).\n",
    "    setOutputCol(\"features\")\n",
    "\n",
    "val clustering = new KMeans().\n",
    "    setFeaturesCol(\"features\").\n",
    "    setK(3).\n",
    "    setMaxIter(3)\n",
    "\n",
    "val pipe = new Pipeline().\n",
    "    setStages(Array(assembler, clustering))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the pipeline to find the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val model = pipe.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.472298409215579,108.21832144816237,109.28304991771806,105.66812945693911]\n",
      "[4.512367491166078,94.31566548881035,81.90106007067138,105.78563015312132]\n",
      "[4.4568835098335855,86.8320726172466,98.22087745839637,77.47957639939486]\n"
     ]
    }
   ],
   "source": [
    "model.stages(1).asInstanceOf[KMeansModel].clusterCenters.foreach { println }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will not be included in the Spark app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(vecAssembler_acf9d1dd4a58, kmeans_279eb22adacb)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//NOT-FOR-APP\n",
    "model.stages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDAX - Scala",
   "language": "scala",
   "name": "idax-scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
